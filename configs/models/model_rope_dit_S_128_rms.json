{
    "_class_name": "RopeDiTTransformer2DModel",
    "num_attention_heads": 6,
    "attention_head_dim": 64,
    "num_layers": 12,
    "in_channels": 3,
    "out_channels": 3,
    "patch_size": 1,
    "sample_size": 128,
    "axes_dims_rope": [
        32,
        32
    ],
    "qk_norm": "rms_norm",
    "rope_size": 128
}